---
title: "Variational Bayesian Inference"
author: ''
date: '2021-04-27'
slug: variational-bayesian-inference
categories: []
tags: []
subtitle: ''
summary: ''
authors: []
lastmod: '2021-04-27T13:22:47-05:00'
featured: no
image:
  caption: ''
  focal_point: ''
  preview_only: no
projects: []
draft: true
---



The goal of variational inference is to replace the computationally expensive task of full Bayesian inference using Markov Chain Monte Carlo (MCMC) with a less computationally expensive optimization of an approximate distribution.

Given a likelihood $p(\mathbf{y} | \boldsymbol{\theta})$ and prior $p(\boldsymbol{\theta})$, the posterior distribution is

\begin{align*}
p(\boldsymbol{\theta} | \mathbf{y}) = \frac{p(\mathbf{y} | \boldsymbol{\theta}) p(\boldsymbol{\theta})}{\int p(\mathbf{y} | \boldsymbol{\theta}) p(\boldsymbol{\theta}) d \boldsymbol{\theta}}
\end{align*}

In general, calculating (or sampling from) the posterior distribution can be computationally challenging. 










